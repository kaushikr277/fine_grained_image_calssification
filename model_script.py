# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1coRj0FV3Ag44GWzCJ4qXM8mYx8311tBn
"""

#this part mount google drive to colab
import os
import tarfile
from google.colab import drive
drive.mount('/content/gdrive/')
import os
os.mkdir('dataset')

#%%
#train test split
imgpath = '/Users/byronleung/Downloads/postgraduate study/下学期/机器学习/归档/Images'
output_ = '/Users/byronleung/Downloads/postgraduate study/下学期/机器学习/dataset'
import split_folders
#%%
# Split with a ratio.
split_folders.ratio(imgpath, output=output_, seed=1337, ratio=(.80, .1, .1))#ratio of train,validation and test
#%%

from keras.preprocessing.image import ImageDataGenerator
train_dir = 'gdrive/My Drive/dataset/train'
test_dir = 'gdrive/My Drive/dataset/test'
vali_dir = 'gdrive/My Drive/dataset/val'
train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45
                                 ,width_shift_range=0.2
                                 ,height_shift_range=0.2,shear_range=0.2

                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode="nearest")
test_datagen=ImageDataGenerator(rescale=1./255)
vali_datagen = ImageDataGenerator(rescale=1./255)
train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20
                                                  ,class_mode="sparse")#return 2D one-hot label
validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode="sparse")
test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode="sparse")

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import models
from keras import layers

"""resnet50"""

from keras.preprocessing.image import ImageDataGenerator
train_dir = 'gdrive/My Drive/dataset/train'
test_dir = 'gdrive/My Drive/dataset/test'
vali_dir = 'gdrive/My Drive/dataset/val'
train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45
                                 ,width_shift_range=0.2
                                 ,height_shift_range=0.2,shear_range=0.2

                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode="nearest")
test_datagen=ImageDataGenerator(rescale=1./255)
vali_datagen = ImageDataGenerator(rescale=1./255)
train_generator=train_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=20
                                                  ,class_mode="sparse")#return 2D one-hot label
validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(224,224),batch_size=20,class_mode="sparse")
test_generator=test_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=20,class_mode="sparse")
from keras.applications.resnet50 import resnet50
resnetmodel = keras.applications.resnet.ResNet50(include_top=True, weights='imagenet'
                                   , input_tensor=None, input_shape=None #default shape(224,224)
                                   , pooling='avg')
                                                 # , classes=120)
resnetmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.SGD(),metrics=['accuracy'])
reshistory = resnetmodel.fit_generator(
    train_generator,
    steps_per_epoch=None,
    epochs=30,
    validation_data=validation_generator,
    validation_steps=None)

"""Vgg16"""

from keras.applications.vgg16 import vgg16
vggmodel = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet',
                                input_tensor=None, input_shape=None,
                                pooling=None,
                                classes=1000)
vggmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.SGD(),metrics=['accuracy'])
vggmodel.summary()
vgghistory = vggmodel.fit_generator(
    train_generator,
    steps_per_epoch=None,
    epochs=30,
    validation_data=validation_generator,
    validation_steps=None)



"""xception"""

import keras
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
train_dir = 'gdrive/My Drive/dataset/train'
test_dir = 'gdrive/My Drive/dataset/test'
vali_dir = 'gdrive/My Drive/dataset/val'
train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45
                                 ,width_shift_range=0.2
                                 ,height_shift_range=0.2,shear_range=0.2
                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode="nearest")
test_datagen=ImageDataGenerator(rescale=1./255)
vali_datagen = ImageDataGenerator(rescale=1./255)
train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20
                                                  ,class_mode="sparse")#return 2D one-hot label
validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode="sparse")
test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode="sparse")
from keras.applications.xception import xception
xmodel = keras.applications.xception.Xception(include_top=True, weights='imagenet'
                                              , input_tensor=None, input_shape=None, pooling=None, classes=1000)
##%
xmodel.compile(loss='sparse_categorical_crossentropy',optimizer = optimizers.SGD(),metrics=['accuracy'])
#%%
xhistory = xmodel.fit_generator(
    train_generator,
    steps_per_epoch=None,
    epochs=30,
    validation_data=validation_generator,
    validation_steps=None)

import matplotlib.pyplot as plt

plt.plot(xhistory.history['accuracy'])
plt.plot(xhistory.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','val'], loc='upper left')
plt.show()

xmodel.save('/content/gdrive/My Drive/xmodel.h5')
xmodel.save_weights('/content/gdrive/My Drive/xmodel_weight.h5')

import keras
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
train_dir = 'gdrive/My Drive/dataset/train'
test_dir = 'gdrive/My Drive/dataset/test'
vali_dir = 'gdrive/My Drive/dataset/val'
train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45
                                 ,width_shift_range=0.2
                                 ,height_shift_range=0.2,shear_range=0.2
                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode="nearest")
test_datagen=ImageDataGenerator(rescale=1./255)
vali_datagen = ImageDataGenerator(rescale=1./255)
train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20
                                                  ,class_mode="sparse")#return 2D one-hot label
validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode="sparse")
test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode="sparse")
from keras.applications.xception import xception
sgdn = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)#with nesterov as optimizer

xmodel_1 = keras.applications.xception.Xception(include_top=True, weights='imagenet'
                                              , input_tensor=None, input_shape=None, pooling=None, classes=1000)
##%
xmodel_1.compile(loss='sparse_categorical_crossentropy',optimizer = sgdn,metrics=['accuracy'])
#%%
xhistory_1 = xmodel_1.fit_generator(
    train_generator,
    steps_per_epoch=None,
    epochs=30,
    validation_data=validation_generator,
    validation_steps=None)

import matplotlib.pyplot as plt

plt.plot(xhistory_1.history['accuracy'])
plt.plot(xhistory_1.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','val'], loc='upper left')
plt.show()

xmodel_1.save('/content/gdrive/My Drive/xmodel_1.h5')
xmodel_1.save_weights('/content/gdrive/My Drive/xmodel_1_weight.h5')



from keras.utils import plot_model
plot_model(xmodel_1, to_file='xmodel-1.jpg', show_shapes=True, show_layer_names=True) # plot my model

from keras.models import load_model
xmodel_1 = load_model('gdrive/My Drive/xmodel_1.h5')

import keras
from keras.applications.xception import xception
from keras import optimizers
sgdn = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)#with nesterov as optimizer

xmodel_1 = keras.applications.xception.Xception(include_top=True, weights='imagenet'
                                              , input_tensor=None, input_shape=None, pooling=None, classes=1000)

xmodel_1.trainable = False

xmodel_1.layers.pop()
# xmodel_1.summary()
# predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]

import keras
xmodel_2 = keras.models.Sequential([        
    xmodel_1,   
    # keras.layers.Flatten(),                     
    keras.layers.Dense(2048,activation="relu"),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(120, activation="softmax")
])
xmodel_2.summary()

xmodel_2.load_weights(r'/content/gdrive/My Drive/xmodel_1_weight.h5',
                   by_name=True)
xmodel_2.trainable = True

import keras
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
train_dir = 'gdrive/My Drive/dataset/train'
test_dir = 'gdrive/My Drive/dataset/test'
vali_dir = 'gdrive/My Drive/dataset/val'
train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=45
                                 ,width_shift_range=0.2
                                 ,height_shift_range=0.2,shear_range=0.2
                                 ,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode="nearest")
test_datagen=ImageDataGenerator(rescale=1./255)
vali_datagen = ImageDataGenerator(rescale=1./255)
train_generator=train_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20
                                                  ,class_mode="sparse")#return 2D one-hot label
validation_generator=vali_datagen.flow_from_directory(vali_dir,target_size=(299,299),batch_size=20,class_mode="sparse")
test_generator=test_datagen.flow_from_directory(train_dir,target_size=(299,299),batch_size=20,class_mode="sparse")
# from keras.applications.xception import xception
# sgdn = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)#with nesterov as optimizer

# xmodel_1 = keras.applications.xception.Xception(include_top=True, weights='imagenet'
#                                               , input_tensor=None, input_shape=None, pooling=None, classes=1000)
##%
xmodel_2.compile(loss='sparse_categorical_crossentropy',optimizer = sgdn,metrics=['accuracy'])
#%%
xhistory_3 = xmodel_2.fit_generator(
    train_generator,
    steps_per_epoch=None,
    epochs=30,
    # callbacks=keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True), #add early stopping
    validation_data=validation_generator,
    validation_steps=None)

xmodel_2.save('/content/gdrive/My Drive/xmodel_2.h5')
xmodel_2.save_weights('/content/gdrive/My Drive/xmodel_2_weight.h5')

import matplotlib.pyplot as plt

plt.plot(xhistory_3.history['accuracy'])
plt.plot(xhistory_3.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','val'], loc='upper left')
plt.show()

from keras.utils import plot_model
plot_model(xmodel_2, to_file='xmodel-2.jpg', show_shapes=True, show_layer_names=True) # plot my model

xmodel_2.summary()

from keras.utils.np_utils import to_categorical
from sklearn.metrics import confusion_matrix
from keras.models import load_model
import matplotlib.pyplot as plt
import itertools
import sklearn.metrics as metrics
import numpy as np
import pandas as pd

model = xmodel_2

# model = load_model('xmodel.h5')
preds = np.round(model.predict(test_generator), 0)  # Predictions on test_generator, arrays with shape (2153,120)

nb_test_samples = len(test_generator.filenames)  # Number of test images
num_classes = len(test_generator.class_indices)  # Number of test breeds
test_labels = test_generator.classes
test_labels = to_categorical(test_labels, num_classes=num_classes)   # Turning test labels into arrays of shape (2153,120)

cat_labels = pd.DataFrame(test_labels).idxmax(axis=1)   # Working with pandas data frames
cat_preds = pd.DataFrame(preds).idxmax(axis=1) 
conf = confusion_matrix(cat_labels, cat_preds)  # Confusion Matrix

## Confusion Matrix Plot
def plot_confusion_matrix(cm,
   normalize=False,
   title="Confusion matrix",
   cmap=plt.cm.Blues):
 
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print("Confusion matrix, without normalization")

    # print(cm)
    plt.figure(figsize=(20,20))
    plt.imshow(cm, interpolation="nearest", cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)

    fmt = ".2f" if normalize else "d"
    thresh = cm.max() / 2.
#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
#           plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel("True label")
    plt.xlabel("Predicted label") 
    plt.show()
    plt.savefig("Conf_Matrix")
    
labels = (train_generator.class_indices) # train_generator.classes
labels = dict((v,k) for k,v in labels.items())    
classes = list(labels.keys())
plot_confusion_matrix(conf, classes)

## Classification Report
from sklearn.metrics import classification_report as classification_report
labels = (train_generator.class_indices) # train_generator.classes
labels = dict((v,k) for k,v in labels.items())    
classes = list(labels.keys())
classification_metrics = classification_report(test_labels, preds)
# , target_names = classes)
print(classification_metrics)

## Model evaluation on the test set
eva = model.evaluate(test_generator)
print(eva)

## Visualise Model's Accuracy on train and validation

import matplotlib.pyplot as plt

plt.plot(xhistory_3.history['accuracy'])
plt.plot(xhistory_3.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','val'], loc='upper left')
plt.show()

## Visualise Model's Loss on train and validation
plt.plot(xhistory_3.history['loss'])
plt.plot(xhistory_3.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show
plt.savefig("Loss_train_val")

preds = np.round(model.predict(test_generator), 0)  # Predictions on test_generator, arrays with shape (2153,120)

nb_test_samples = len(test_generator.filenames)  # Number of test images
num_classes = len(test_generator.class_indices)  # Number of test breeds
test_labels = test_generator.classes
test_labels = to_categorical(test_labels, num_classes=num_classes)   # Turning test labels into arrays of shape (2153,120)

cat_labels = pd.DataFrame(test_labels).idxmax(axis=1)   # Working with pandas data frames
cat_preds = pd.DataFrame(preds).idxmax(axis=1) 

frames = [cat_labels, cat_preds]

df = pd.concat(frames, axis=1)

df.columns = ['actual', 'pred']

misclass_df = df[df['actual'] != df['pred']].groupby(['actual', 'pred']).sum().sort_values(['Result'], ascending=False).reset_index()
misclass_df['pair'] = misclass_df['actual'] + ' / ' + misclass_df['pred']
misclass_df = misclass_df[['pair', 'Result']].take(range(30))

misclass_df

xmodel_2.save('/content/gdrive/My Drive/xmodel_2.h5')
xmodel_2.save_weights('/content/gdrive/My Drive/xmodel_2_weight.h5')
